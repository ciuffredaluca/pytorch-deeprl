{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN playing basketball\n",
    "\n",
    "In this notebook we show how to train a DQN agent to play [Atari DoubleDunk](https://gym.openai.com/envs/DoubleDunk-v0/), using screen pixels as state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from gym import wrappers\n",
    "from gym.wrappers.monitor import load_results\n",
    "import datetime\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'running session on {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not '..' in sys.path:\n",
    "    sys.path.append('..')\n",
    "\n",
    "from deeprl.agents import DQN, ReplayMemory\n",
    "from deeprl.experiment import LearningParams, Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENT_PARAMETERS = LearningParams({ \n",
    "                                    'BATCH_SIZE' : 128,\n",
    "                                    'GAMMA' : 0.999,\n",
    "                                    'EPS_START' : 0.9,\n",
    "                                    'EPS_END' : 0.05,\n",
    "                                    'EPS_DECAY' : 200,\n",
    "                                    'TARGET_UPDATE' : 10\n",
    "                                  })\n",
    "\n",
    "MEMORY_CAPACITY = 10000\n",
    "LOGGING_FOLDER = f'../logs/dqn-experiment-{datetime.datetime.now().strftime(\"%d-%m-%Y_%H:%M:%S\")}'\n",
    "NUM_EPISODES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('DoubleDunk-v0')\n",
    "\n",
    "# wrap environment for logging\n",
    "env = wrappers.Monitor(env = env, \n",
    "                       directory = LOGGING_FOLDER, \n",
    "                       mode='training', \n",
    "                       force=True, \n",
    "                       write_upon_reset=False)\n",
    "\n",
    "# REMARK: in order to save every episode video pass argument\n",
    "#     video_callable=lambda episode_id: True\n",
    "# see: https://github.com/openai/gym/issues/494"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define replay memory\n",
    "memory = ReplayMemory(capacity=MEMORY_CAPACITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image preprocessing\n",
    "screen_transform = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(84, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = Experiment(env = env, \n",
    "                  model_class = DQN,\n",
    "                  params = AGENT_PARAMETERS,\n",
    "                  device = device,\n",
    "                  memory = memory,\n",
    "                  screen_transform = screen_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(num_episodes=NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize logged results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_results(LOGGING_FOLDER)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-rl] *",
   "language": "python",
   "name": "conda-env-deep-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
